{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "print(xgb.__version__)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300000 entries, 0 to 299999\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   Transaction.Date    300000 non-null  object \n",
      " 1   Transaction.Amount  300000 non-null  float64\n",
      " 2   Customer.Age        300000 non-null  int64  \n",
      " 3   Is.Fraudulent       300000 non-null  int64  \n",
      " 4   Account.Age.Days    300000 non-null  int64  \n",
      " 5   Transaction.Hour    300000 non-null  int64  \n",
      " 6   source              300000 non-null  object \n",
      " 7   browser             300000 non-null  object \n",
      " 8   sex                 300000 non-null  object \n",
      " 9   Payment.Method      300000 non-null  object \n",
      " 10  Product.Category    300000 non-null  object \n",
      " 11  Quantity            300000 non-null  int64  \n",
      " 12  Device.Used         300000 non-null  object \n",
      " 13  Address.Match       300000 non-null  int64  \n",
      "dtypes: float64(1), int64(6), object(7)\n",
      "memory usage: 32.0+ MB\n",
      "\n",
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Load the dataset\n",
    "df = pd.read_csv('/Users/saivyshnavigudipalli/Documents/604 assignmnet classwork/merged_dataset (1).csv')\n",
    "\n",
    "df.head()\n",
    "\n",
    "#check data type\n",
    "\n",
    "df.info()\n",
    "\n",
    "#Identifying the features and the target varibale\n",
    "\n",
    "X = df.drop(columns=['Is.Fraudulent'])\n",
    "y = df['Is.Fraudulent']\n",
    "\n",
    "#check for missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "# Check for duplicate rows\n",
    "duplicate_rows = df.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicate rows: {duplicate_rows}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset After Preprocessing:\n",
      "    Transaction.Amount  Customer.Age  Is.Fraudulent  Account.Age.Days  \\\n",
      "0              145.98            29              0               172   \n",
      "1              677.62            40              0               250   \n",
      "2              798.63            40              0               118   \n",
      "3              314.65            34              0               187   \n",
      "5              182.91            21              0               143   \n",
      "\n",
      "   Transaction.Hour  source  browser  sex  Payment.Method  Product.Category  \\\n",
      "0                10       0        2    0               2                 3   \n",
      "1                22       1        1    1               2                 0   \n",
      "2                20       0        0    1               0                 0   \n",
      "3                23       2        2    1               1                 4   \n",
      "5                 5       1        1    0               3                 1   \n",
      "\n",
      "   Quantity  Address.Match  \n",
      "0         3              1  \n",
      "1         3              1  \n",
      "2         3              1  \n",
      "3         3              1  \n",
      "5         3              1  \n",
      "✅ Data Cleaning & Preprocessing Completed!\n",
      "\n",
      "Dataset After Preprocessing:\n",
      "    Transaction.Amount  Customer.Age  Is.Fraudulent  Account.Age.Days  \\\n",
      "0              145.98            29              0               172   \n",
      "1              677.62            40              0               250   \n",
      "2              798.63            40              0               118   \n",
      "3              314.65            34              0               187   \n",
      "5              182.91            21              0               143   \n",
      "\n",
      "   Transaction.Hour  source  browser  sex  Payment.Method  Product.Category  \\\n",
      "0                10       0        2    0               2                 3   \n",
      "1                22       1        1    1               2                 0   \n",
      "2                20       0        0    1               0                 0   \n",
      "3                23       2        2    1               1                 4   \n",
      "5                 5       1        1    0               3                 1   \n",
      "\n",
      "   Quantity  Address.Match  \n",
      "0         3              1  \n",
      "1         3              1  \n",
      "2         3              1  \n",
      "3         3              1  \n",
      "5         3              1  \n"
     ]
    }
   ],
   "source": [
    "#As we can see from above that there are 5 categorical variables we are going to use label encoding to change it to numerical values\n",
    "\n",
    "#Convert categorical variables to numeric \n",
    "\n",
    "\n",
    "categorical_cols = ['source', 'browser', 'sex', 'Payment.Method', 'Product.Category']\n",
    "\n",
    "df = df[df['Transaction.Amount'] >= 0]  # No negative transactions\n",
    "df = df[(df['Customer.Age'] >= 18) & (df['Customer.Age'] <= 100)]  # Reasonable age range\n",
    "df = df[df['Account.Age.Days'] >= 0]  # No negative account age\n",
    "df = df[(df['Transaction.Hour'] >= 0) & (df['Transaction.Hour'] < 24)]  # Valid hour range\n",
    "\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()  # Create an encoder for the column\n",
    "    df[col] = le.fit_transform(df[col])  # Convert text labels into numbers\n",
    "    label_encoders[col] = le  # Store the encoder for future use\n",
    "\n",
    "    #Handle any missing or incorrect values\n",
    "\n",
    "df = df[df['Customer.Age'] >= 0] # Remove negative ages\n",
    "    # 4️⃣ Drop Irrelevant Columns (e.g., timestamps if present)\n",
    "irrelevant_cols = ['Transaction.Timestamp'] if 'Transaction.Timestamp' in df.columns else []\n",
    "df.drop(columns=irrelevant_cols, inplace=True)\n",
    "\n",
    "df = df.drop(columns=['Transaction.Date', 'Device.Used'])\n",
    "\n",
    "\n",
    "# 5️⃣ Check the final dataset\n",
    "print(\"\\nDataset After Preprocessing:\\n\", df.head())\n",
    "print(\"✅ Data Cleaning & Preprocessing Completed!\")\n",
    "\n",
    "print(\"\\nDataset After Preprocessing:\\n\", df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9535\n",
      "Precision: 0.8566\n",
      "Recall: 0.4136\n",
      "F1-Score: 0.5579\n",
      "ROC-AUC Score: 0.7955\n",
      "Confusion Matrix:\n",
      "[[54195   288]\n",
      " [ 2440  1721]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score,f1_score,roc_auc_score,confusion_matrix\n",
    "\n",
    "#Split the dataset \n",
    "\n",
    "X= df.drop(columns=['Is.Fraudulent'])\n",
    "y= df['Is.Fraudulent']\n",
    "\n",
    "# Split into training and testing sets (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize XGBoost classifier without 'use_label_encoder'\n",
    "xgb_model = xgb.XGBClassifier(eval_metric='logloss')\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "#Evaluate the model using different metrics\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f'Precision: {precision:.4f}')\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f'Recall: {recall:.4f}')\n",
    "\n",
    "# F1-Score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f'F1-Score: {f1:.4f}')\n",
    "\n",
    "# ROC-AUC Score\n",
    "roc_auc = roc_auc_score(y_test, xgb_model.predict_proba(X_test)[:, 1])  # Probabilities for positive class\n",
    "print(f'ROC-AUC Score: {roc_auc:.4f}')\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
